# Классификация токсичных комментариев для интернет-магазина «Викишоп»

## О проекте

Проект по разработке системы автоматического обнаружения токсичных комментариев для интернет-магазина «Викишоп». Система анализирует пользовательские правки товаров и отправляет потенциально токсичные комментарии на модерацию.

##  Цели проекта

- Разработка модели классификации комментариев на токсичные и нетоксичные
- Достижение значения F1-score ≥ 0.75 на тестовой выборке
- Сравнение классических методов ML и современных трансформерных подходов
- Обеспечение высокой точности обнаружения для уменьшения нагрузки на модераторов

##  Данные

### Источник данных:
Набор данных с разметкой о токсичности комментариев

### Структура данных:
- Текстовые комментарии пользователей
- Бинарная разметка: токсичный (1) / нетоксичный (0)
- Предобработанные данные: лемматизация выполнена заранее

##  Технологии

### Классические методы:
- **Python 3.8+**
- **Pandas/NumPy** - обработка данных
- **Scikit-learn** - машинное обучение
- **TF-IDF** - векторное представление текста
- **NLTK** - лингвистическая обработка

### Современные подходы:
- **BERT** (sentence-transformers) - семантические эмбеддинги
- **Transformers** - современные NLP модели
- **Sentence-Transformers** - библиотека для работы с эмбеддингами

### Визуализация:
- **Matplotlib/Seaborn** - графики и диаграммы
- **WordCloud** - облака слов для анализа лексики

##  Ключевые этапы работы

### 1. Предобработка данных
- Анализ и очистка текстовых данных
- Лемматизация (выполнена заранее)
- Балансировка классов при необходимости
- Разделение на train/test (80/20) с сохранением временного порядка

### 2. Feature Engineering
- **TF-IDF векторизация**:
  - Максимальное количество features: 10,000
  - Униграммы и биграммы: ngram_range=(1,2)
  - Нормализация и взвешивание терминов

- **BERT эмбеддинги**:
  - Модель: 'paraphrase-MiniLM-L6-v2'
  - Семантическое векторное представление
  - Размерность: 384 features

### 3. Обучение моделей

#### Классические алгоритмы:
- **Logistic Regression** - линейная классификация
- **Ridge Classifier** - регуляризованная классификация  
- **Linear SVC** - метод опорных векторов
- **Stacking Classifier** - ансамбль моделей

#### Современные подходы:
- **BERT + Logistic Regression** - комбинированный подход
- Fine-tuning порога классификации для оптимизации F1-score

### 4. Оценка и оптимизация
- Кросс-валидация и подбор гиперпараметров
- Анализ метрик: F1, Precision, Recall, Accuracy
- Оптимизация порога классификации
- Интерпретация важности признаков

##  Результаты

### Сравнение моделей:

| Модель | F1-score (токсичные) | Precision | Recall |
|--------|---------------------|-----------|--------|
| **Stacking Classifier** | **0.77** | 0.88 | 0.69 |
| **BERT + Logistic Regression** | 0.69 | 0.62 | 0.78 |
| Logistic Regression | 0.75 | 0.85 | 0.67 |
| Ridge Classifier | 0.74 | 0.84 | 0.66 |

### Ключевые достижения:
- ✅ **Цель достигнута**: F1-score = 0.77 > 0.75
- ✅ **Высокая точность**: Precision = 0.88 (мало ложных срабатываний)
- ✅ **Практическая применимость**: Модель готова к внедрению

##  Анализ результатов

### Stacking Classifier (лучшая модель):
- **Преимущества**: Лучший баланс между точностью и полнотой
- **Архитектура**: Ансамбль из LogisticRegression, RidgeClassifier, LinearSVC
- **Интерпретируемость**: Возможность анализа важности признаков

### BERT подход:
- **Преимущества**: Лучшее понимание контекста и семантики
- **Недостатки**: Требует больше вычислительных ресурсов
- **Перспективы**: Возможность fine-tuning для улучшения результатов

### Лингвистический анализ:
- **Токсичные комментарии**: Содержат агрессивную лексику, оскорбления
- **Нетоксичные комментарии**: Конструктивные предложения, благодарности
- **Ключевые слова**: Выявлены через анализ важности TF-IDF признаков
